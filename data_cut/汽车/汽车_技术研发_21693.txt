在硅谷 无人驾驶技术正上演“三国演义”　　下一个驾驶时代，大致就如梅赛德斯奔驰在上一届CES所展示的那样：无人驾驶的车里，人们或阅读或举杯相庆。但还要多久，机器驾驶的车辆才能够普及于众人？不仅驾驶者更为自由和安全，整个交通体系也会因此提高效率。　　目前来看，最大的难点在于让它们能够像人一样“看得见”，一旦越过这一障碍，科幻电影里《少数派报告》、《遗落战境》里的驾驶场景很可能会变成现实。　　无人驾驶代替司机　　在考虑无人驾驶的必要性上，我得出的答案是它能给人更大的自由——无需你驾驶，但跟公共交通相比，它是专属个人的，路线上完全服务个人，也较好地保护隐私，而以往要实现这些，你可能需要雇一名司机。是的，现代科技一个重要的特点就是以机器和算法代替人力，让机器和算法为普通民众做那些以往精英阶层家庭佣人为他们做的事情。　　只需要看Uber在这一领域的动作，就能知道这件事情的必要性：2015年5月，Uber把卡内基梅隆大学机器人实验室里所有与自动驾驶有关的人员都招走了，包括研发人员、市场专家等50多人，除此之外，还在离实验室不到1英里（约合1.61公里）远的地方租了53000平方英尺（约合4923.86平方米）的地方，搭建了个技术中心。　　人力成本之高，是美国产生分享经济的重要原因之一。让闲暇的拥有私家车车主按照他们的指令载客，再向这些赚到车费的司机收取佣金，是Uber这个独角兽公司的盈利模式。毫无疑问，如果无人驾驶能够代替司机，这将为这家公司带来新的拥有更高利润率的盈利模式。　　不仅仅是Uber，Google打着“让生活更美好”的目的一直在积极推动这项技术。这两年来Google一直像遛宠物一样让公司研发的无人车在美国山景城行驶，更是让世人知道这家公司在这一领域的作为。据《卫报》报道，Google成立了自己的汽车公司Google Auto，打算量产那款外形可爱的无人驾驶汽车。　　值得注意的是，中国互联网巨头百度在这一领域也有所涉足。就在2015年12月，百度让公司研发的无人驾驶车辆在路况复杂的北京行驶。在技术上，百度的无人驾驶车辆并没有超越Google之处，但不能忽视一家中国公司在技术普及上的推动力。　　触觉与视觉之争　　目前来说，无人驾驶主要有两种路径，一种是靠“触觉”，另一种是依靠“视觉”。　　“触觉”就是靠雷达。正如所见，在山景城附近溜达的谷歌无人驾驶车头上顶着一个黑色的雷达，百度的车也是如此，他们依靠车上雷达，通过激光扫描，判断出周围障碍物的远近。　　“雷达这种方式比较容易得出比如说前面的障碍物有多远这类结果，不需要太大的计算量。”百度硅谷研究院杰出科学家徐伟在接受界面新闻采访时指出，这种路径有它固有的弱点。“雷达探测，它只能知道前面有个东西，很难知道比如前面的车道线在什么地方，它也无法识别周围的一些交通标识牌”。　　目前这种依靠雷达的无人驾驶技术路径在很大程度上依赖高精度地图，毫无疑问，使用非常受限。而目前宣称在多少年之内将无人驾驶车辆商用的公司，比如百度，计划的也是扩大高精度地图覆盖范围。　　即便是Google的车辆，看起来在山景城附近溜达得悠然自得，但实际上这并不具备可复制性。Google为汽车装备了经过强化的山景城街景，城市的虚拟地图，通过这种方式，无人驾驶的车辆明确知道街道是什么样，只需要靠雷达探测出比如汽车和行人等障碍物。截至目前，Google仅绘制了全美400万英里（约合643.73万公里）道路中的2000英里（约合3128.68公里），这个目标可谓任重而道远。　　除此之外，依靠雷达探测的车辆硬件成本也十分高昂，根据Techinsider的调查，单个激光测距系统的价格就要8万美元（约合51.90万元人民币）左右。　　包括Tesla在内的一些厂商认为，未来无人驾驶的方向应该是依靠“视觉”，即涉及深度学习算法的图像识别。“这时机器就像人一样，能够识别图象，然后决定该怎么做。很大程度上依赖深度学习，因为现在大量的计算机视觉的算法背后都是深度学习。”徐伟表示。　　这种路径没有被采用的原因在于目前技术还达不到“无人驾驶”的水准。“它的精度还没有达到自动驾驶的要求，比如说对于判断前方的车体距离的监测还没有雷达做得好，另一方面它的计算量还远远超过雷达那样的系统的计算量。”徐伟在百度硅谷研究院从事的正是计算机视觉方面的研究，应用到无人驾驶车辆上是他们研究应用的方向之一。图像识别在一定程度上解决了雷达路径无法识别交通标识、依靠高精度地图以及价格昂贵等问题。　　Elon Musk就是这一路径的坚决支持者，它在指责Google路径错误的同时，采用了两种路径结合的方式，从Tesla向外界揭露的无人驾驶汽车来看，采用高速摄像头让汽车“看得见”，识别车道、交通标识，此外，仍然采用了12个雷达，感知汽车周围的车辆和其他障碍物。　　看上去，Musk还希望通过现有的Tesla车主去“训练”未来将使用的自动驾驶系统，让人训练机器，让机器越来越像人是目前涉及深度学习算法的常用路径——Facebook就聘请了一群合同工来训练即将推出依赖机器学习的虚拟助手“M”。　　机器像人一样看得见　　无人驾驶时代迟早都会到来，这是包括徐伟在内的这群科学家所坚信的。“最终形态应该是像人一样，看见了什么，能够做出判断如何做反应，不需要很精确很精确的地图。”　　像徐伟这样的科学家正致力于让机器具备“像人一样看得见”的能力——这种大多数哺乳动物天生具有的能力。世界上几乎所有动物都有眼睛，都能以某种方式看见这个世界，即便是昆虫，它大脑比人类简单得多，都知道在看见后如何做出应对，而不需要强大计算能力——是进化让他们先天具有这种功能。　　让汽车达到像人一样还有很长的路要走，比如漂浮在高速公路上的纸非常显眼，却没有危险性可言。　　更重要的是驾驶时很大程度涉及驾驶者之间或者驾驶者和行人之间的关系、交流，而这种交流往往是一个细微的表情甚至是一个眼神，比如驾驶者常常微笑示意正要过马路的行人先走。对于机器而言，识别一个类似小动作可谓是困难重重。　　谷歌最近公布的一个报告表示，自2009年测试无人驾驶车以来，总计被撞击14次，包括11起追尾事故。该公司特别强调，在所有车祸中，谷歌自动驾驶车都是无过错一方。但在我们看来，不排除一种可能是，如果是人在开车，司机和司机之间有有效的交流，一部分事故是能够避免的。　　毫无疑问，无人驾驶车辆一旦较大规模上路，既往所遵循的一些驾驶习惯甚至是交通条款都可能面临改变。而可以预见的是，当人驾驶的车辆和无人驾驶车辆混合时，会有一定的麻烦，“太笨了，无人驾驶车”，这样抱怨一定不会少。而无人驾驶车辆的最终目的是整体交通效率的提高，这或许需要无人驾驶车在整体行驶的车辆中达到某个比例。　　除此之外，目前无人驾驶车辆往往陷入一个伦理困境，“司机”必须决定是右转撞上三个在卡车内的人，还是左转可能会撞死一个骑摩托车的人？　　实际上，这种道德困境在目前人驾驶的情况下就出现过，答案当然是无解，而这一争论最终也被各种事故发生时司机的本能反应所取代。而现在，作为无人驾驶汽车，需要程序员们对这个争论做出回答——他们需要先对此编程，告诉汽车在面对这种状况时如何做出反应。　　除此之外，程序员还需要给出另外的进退维谷的答案包括在面临危险时保护乘客还是保护行人？　　“问题在于，谁来决定我们想要的结果？”Jeffrey Miller，一位编写自动驾驶软件的USC专家这样说到，“你不可能作出一个百分之百的双赢决定，说撞右边那个人就是对的。”当然，最终结果有可能从大数据中得出——在既往千千万万事故中那些人类司机是如何做出反应的。但技术公司并不卷入这种争论，他们表示，能够通过技术避免这种“不可避免”的情况发生。（文章来源：车云网）